
# 集群模式概述

为了更加简单地理解Spark涉及的组成部分，这个文档给出了一个对于Spark如何在集群上运行的简短概述。阅读[应用提交指南](http://spark.apache.org/docs/2.0.1/submitting-applications.html)来学习在一个集群上运行应用。

组成部分
---

Spark应用是作为独立的处理集合运行在一个集群上，通过主函序（也叫驱动程序，Driver Program）里的SparkContext对象进行协调。


具体来说，Spark要运行在集群上，SparkContext能够连接到集群管理（Spark的standalone cluster管理Mesos或YARN），它负责对应用分配资源。一旦连接之后，Spark获取集群上节点的执行器（executors），执行器负责计算和存储我们应用的数据。接下来，Spark发送你的应用代码（jar文件）到执行器。最后，SparkContext发送任务（task）到执行器运行。


![Spark cluster  Components](http://spark.apache.org/docs/2.0.1/img/cluster-overview.png)

以下是一些对这个架构的解释有帮助的东西：

1. 每个应用获取它自己拥有的执行器过程，在应用的生命期一直保留，并且以多线程方式运行任务。这有利于在调度方面（每个driver调度它自己的task）和执行器方面（来自不同application的tasks运行在不同的JVMs里）隔离来自不同的应用。然而，这也意味着，在不同的Spark application（SparkContext实例）之间数据不能共享，除非写数据到一个外部存储系统。

2. 运行在集群管理之上的Spark是不可知论的。只要它能获得执行器过程（executor process），这些过程就可以互相交流，它是相对比较简单的，运行在一个也支持其他应用的集群管理上（例如Mesos/YARN）。（Spark is agnostic to the underlying cluster manager. As long as it can acquire executor processes, and these communicate with each other, it is relatively easy to run it even on a cluster manager that also supports other applications (e.g. Mesos/YARN).）

3. 驱动程序（driver program）必须在它的整个生命周斯内，监听并接受来自它的执行器的连接（见[网络配置部分](http://spark.apache.org/docs/2.0.1/configuration.html#networking)的`spark.driver.port`）。同样，驱动程序必须能够被worker节点访问到。

4. 因为在集群上，是驱动调度任务，因此，驱动应该运行在worker节点的附近，在同一个局域网会更好。如果你想发送请求到远程的集群，最好让驱动打开一个RPC，然后从附近提交操作，而不是在离worker很远的节点运行一个驱动。

集群管理类型
--
系统当前支持三种集群管理：
* [Standalone](http://spark.apache.org/docs/2.0.1/spark-standalone.html) - 一个简单的内置在Spark中的集群管理，使得设置一个集群更加简单。

* [Apache Mesos](http://spark.apache.org/docs/2.0.1/running-on-mesos.html) - 一个通用的集群管理，也能运行Hadoop MapReduce和服务应用。

* [Hadoop YARN](http://spark.apache.org/docs/2.0.1/running-on-yarn.html) - Hadoop 2的资源管理。

提交应用
--
使用`spark-submit`脚本可以提交应用到任意类型的集群，[应用提交指南](http://spark.apache.org/docs/2.0.1/submitting-applications.html)描述了如何提交。

监测
--
每个驱动程序有一个web UI，端口号通常为4040，页面显示关于运行任务，执行器，和存储使用的信息。可以在web浏览器里打开并访问这个UI，链接地址为：`http://<driver-node>:4040`，[监测指南](http://spark.apache.org/docs/2.0.1/monitoring.html)描述了其他的监测选项。

术语
--

| 术语 | 含义 |
| ----- |:-------:| -----:|
|Application(应用)|Spark用户程序，包含一个驱动程序和集群上的执行器。|
|Application jar(应用jar)|一个jar包含了用户的spark应用，在一些情况下，用户想创建一个‘uber jar’,这个jar包包含了应用所需的信赖，但从来不需要加入Hadoop和Spark的库包，因为这些库会在运行的时候自动加入。|
|Driver Program(驱动程序)|运行应用的主函数和创建SparkContext的过程。|
|Cluster Manager(集群管理)|在集群上获取资源的额外服务（例如Standalone,Mesos,Yarn）。|
|Deploy mode(部署模式)|区别在于驱动运行在哪，在‘cluster’模式，框架在集群内运行驱动，在‘client’模式，提交运行的驱动运行在集群外部。|
|Worker Node(工作节点)|在集群中，可以运行应用代码的任意节点。|
|Excutor（执行者）|在工作节点，应用执行的一个过程，这个过程运行任务，并且将数据存储在内存或磁盘上，每个应用有它自己的执行者。|
|Task(任务)|发送给执行者的工作单元。|
|Job(作业)|包含多任务的并行计算，这些任务由spark行动（action,例如save,collect等）产生。|
|Stage(阶段)|每个Job被分割成更小的任务集合，stage之间相互信赖（类似于Hadoop里的map和reduce阶段），在驱动的日志文件里，可以看到这些术语。|
