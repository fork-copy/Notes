
# 集群模式概述

为了更加简单地理解Spark涉及的组成部分，这个文档给出了一个对于Spark如何在集群上运行的简短概述。阅读[应用提交指南](http://spark.apache.org/docs/2.0.1/submitting-applications.html)来学习在一个集群上运行应用。

组成部分
---

Spark应用是作为独立的处理集合运行在一个集群上，通过主函序（也叫驱动程序，Driver Program）里的SparkContext对象进行协调。


具体来说，Spark要运行在集群上，SparkContext能够连接到集群管理（Spark的standalone cluster管理Mesos或YARN），它负责对应用分配资源。一旦连接之后，Spark获取集群上节点的执行器（executors），执行器负责计算和存储我们应用的数据。接下来，Spark发送你的应用代码（jar文件）到执行器。最后，SparkContext发送任务（task）到执行器运行。


![Spark Components](http://spark.apache.org/docs/2.0.1/img/cluster-overview.png)

以下是一些对这个架构的解释有用的东西：

1. 每个应用获取它自己拥有的执行器过程，

Each application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads. This has the benefit of isolating applications from each other, on both the scheduling side (each driver schedules its own tasks) and executor side (tasks from different applications run in different JVMs). However, it also means that data cannot be shared across different Spark applications (instances of SparkContext) without writing it to an external storage system.

Spark is agnostic to the underlying cluster manager. As long as it can acquire executor processes, and these communicate with each other, it is relatively easy to run it even on a cluster manager that also supports other applications (e.g. Mesos/YARN).

The driver program must listen for and accept incoming connections from its executors throughout its lifetime (e.g., see spark.driver.port in the network config section). As such, the driver program must be network addressable from the worker nodes.

Because the driver schedules tasks on the cluster, it should be run close to the worker nodes, preferably on the same local area network. If you’d like to send requests to the cluster remotely, it’s better to open an RPC to the driver and have it submit operations from nearby than to run a driver far away from the worker nodes.
